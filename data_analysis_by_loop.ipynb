{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from azure.storage.blob import BlobServiceClient, generate_account_sas, ResourceTypes, AccountSasPermissions, BlobBlock\n",
    "from datetime import datetime, timedelta, date\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "from collections import deque\n",
    "import dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset from cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dat' has no attribute 'df_read_azure_single_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# df = dat.df_read_aws(\"aws\",\"merkle-de-interview-case-study/de\",\"item.csv\")\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# In case needed df_read_azure method is available in dat package for azure blob reads\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_read_azure_single_file\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdenemefileread\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdanyal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dat' has no attribute 'df_read_azure_single_file'"
     ]
    }
   ],
   "source": [
    "# df = dat.df_read_aws(\"aws\",\"merkle-de-interview-case-study/de\",\"item.csv\")\n",
    "# In case needed df_read_azure method is available in dat package for azure blob reads\n",
    "df = dat.df_read_azure_single_file(\"denemefileread\",\"qjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\",\"event.csv\",\"danyal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'analysis_https:\\\\denemefileread.blob.core.windows.net\\\\danyal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_read_azure_multiple_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdenemefileread\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdanyal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MeliaMuyo\\Desktop\\ALL\\GIRAY\\dat\\data_analysis_tool\\dat\\multiple_dataset_apply_azure.py:50\u001b[0m, in \u001b[0;36mdf_read_azure_multiple_files\u001b[1;34m(storage_account_name, account_key, container_name)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[39mvars\u001b[39m()[key] \u001b[39m=\u001b[39m value(df)\n\u001b[0;32m     49\u001b[0m         \u001b[39m# Saving dataframes consisting of analysis into a single excel file\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m         dat\u001b[39m.\u001b[39;49msave_dataframe_excel(\u001b[39mvars\u001b[39;49m(),\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39manalysis_\u001b[39;49m\u001b[39m{\u001b[39;49;00mFile_name\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mdate\u001b[39m.\u001b[39;49mtoday()\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdataset_analysis_saved\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\MeliaMuyo\\Desktop\\ALL\\GIRAY\\dat\\data_analysis_tool\\dat\\save_dataframe_excel.py:9\u001b[0m, in \u001b[0;36msave_dataframe_excel\u001b[1;34m(df_list, file_name)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m\u001b[39m\u001b[39m''' Saves all active dataframes into an excel sheet \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mcreated in session'''\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mglobal\u001b[39;00m writer\n\u001b[1;32m----> 9\u001b[0m writer \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mExcelWriter(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mfile_name\u001b[39m}\u001b[39;49;00m\u001b[39m.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m, engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mxlsxwriter\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m df_list:\n\u001b[0;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(df_list[i]) \u001b[39m==\u001b[39m pd\u001b[39m.\u001b[39mDataFrame \u001b[39mand\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     12\u001b[0m         \u001b[39m# print(i)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MeliaMuyo\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:199\u001b[0m, in \u001b[0;36mXlsxWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAppend mode is not supported with xlsxwriter!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 199\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    200\u001b[0m     path,\n\u001b[0;32m    201\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m    202\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m    203\u001b[0m     datetime_format\u001b[39m=\u001b[39;49mdatetime_format,\n\u001b[0;32m    204\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m    205\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    206\u001b[0m     if_sheet_exists\u001b[39m=\u001b[39;49mif_sheet_exists,\n\u001b[0;32m    207\u001b[0m     engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[0;32m    208\u001b[0m )\n\u001b[0;32m    210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_book \u001b[39m=\u001b[39m Workbook(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handles\u001b[39m.\u001b[39mhandle, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\MeliaMuyo\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1219\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handles \u001b[39m=\u001b[39m IOHandles(\n\u001b[0;32m   1216\u001b[0m     cast(IO[\u001b[39mbytes\u001b[39m], path), compression\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m   1217\u001b[0m )\n\u001b[0;32m   1218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1220\u001b[0m         path, mode, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1221\u001b[0m     )\n\u001b[0;32m   1222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cur_sheet \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[39mif\u001b[39;00m date_format \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\MeliaMuyo\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\io\\common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 737\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    739\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    740\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    741\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MeliaMuyo\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\io\\common.py:599\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[39mCheck if parent directory of a file exists, raise OSError if it does not\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m    Path to check parent directory of\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m--> 599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39;49mis_dir():\n\u001b[0;32m    600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MeliaMuyo\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\pathlib.py:1415\u001b[0m, in \u001b[0;36mPath.is_dir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[39mWhether this path is a directory.\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1415\u001b[0m     \u001b[39mreturn\u001b[39;00m S_ISDIR(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstat()\u001b[39m.\u001b[39mst_mode)\n\u001b[0;32m   1416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1417\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _ignore_error(e):\n",
      "File \u001b[1;32mc:\\Users\\MeliaMuyo\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\pathlib.py:1197\u001b[0m, in \u001b[0;36mPath.stat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstat\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1193\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[39m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[0;32m   1195\u001b[0m \u001b[39m    os.stat() does.\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1197\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mstat(\u001b[39mself\u001b[39;49m)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'analysis_https:\\\\denemefileread.blob.core.windows.net\\\\danyal'"
     ]
    }
   ],
   "source": [
    "dat.df_read_azure_multiple_files(\"denemefileread\",\"qjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\",\"danyal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             event_id       event_time  user_id  \\\n",
      "0    b9de71c5c3cc4cd7a97e50b832106e5a  6/26/2017 11:23   178481   \n",
      "1    23267713c9ea44419331731f50b6a8db  6/27/2017 10:46   178481   \n",
      "2    1b7822fa7b854e01970218ae8f721fe0  6/27/2017 11:15   178481   \n",
      "3    2a7a188a626841ac94befcc419f06af4  10/5/2016 20:43   154133   \n",
      "4    631d657264cc4616a4528f759509b25d   10/4/2016 3:29   154133   \n",
      "..                                ...              ...      ...   \n",
      "994  381b43fc776647a0bb33693e5bc4c4d4  10/4/2016 16:16   119909   \n",
      "995  73eca6e3d9eb4d0ead7eeb76e6525faa  10/1/2016 10:15   119909   \n",
      "996  a8418cc9dd1c4764a8411e5e7b42a111  10/3/2016 14:07   119909   \n",
      "997  e55dfd6c85d846fe8bd937476f7877e9    7/8/2016 5:29   110128   \n",
      "998  a4f9574c14894c8d9732167760dab92d   7/9/2016 16:28   110128   \n",
      "\n",
      "                                         event.payload  \n",
      "0    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "1    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "2    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "3    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "4    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "..                                                 ...  \n",
      "994  {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "995  {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "996  {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "997  {\"event_name\":\"view_item\",\"platform\":\"iOS\",\"pa...  \n",
      "998  {\"event_name\":\"view_item\",\"platform\":\"iOS\",\"pa...  \n",
      "\n",
      "[999 rows x 4 columns]\n",
      "                adjective     category           created_at      id  \\\n",
      "0                   fuzzy  contraption  2014-01-15 21:36:09  2512.0   \n",
      "1                     NaN   instrument  2013-05-14 05:20:50   482.0   \n",
      "2     industrial-strength       module  2014-02-04 19:28:32  2446.0   \n",
      "3                 digital         tool  2013-02-25 12:23:18  1312.0   \n",
      "4               miniature       device  2013-08-05 17:20:45  3556.0   \n",
      "...                   ...          ...                  ...     ...   \n",
      "2193        prize-winning    apparatus  2013-08-13 04:14:14  3952.0   \n",
      "2194                fuzzy       dongle  2014-01-16 00:58:43   432.0   \n",
      "2195  industrial-strength       dongle  2013-12-18 21:37:01  1393.0   \n",
      "2196            miniature       device  2013-11-27 14:14:47   425.0   \n",
      "2197                  NaN       widget  2013-10-10 21:13:50   325.0   \n",
      "\n",
      "           modifier                               name  price  \n",
      "0     carrying_case    fuzzy contraption carrying_case  150.0  \n",
      "1            refill                  instrument refill   35.2  \n",
      "2               NaN         industrial-strength module  300.0  \n",
      "3     carrying_case         digital tool carrying_case   16.5  \n",
      "4           cleaner           miniature device cleaner   16.5  \n",
      "...             ...                                ...    ...  \n",
      "2193        charger    prize-winning apparatus charger   66.0  \n",
      "2194        wrapper               fuzzy dongle wrapper   12.0  \n",
      "2195         refill  industrial-strength dongle refill   72.0  \n",
      "2196            NaN                   miniature device   27.5  \n",
      "2197  how-to-manual               widget how-to-manual    0.0  \n",
      "\n",
      "[2198 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# https://denemefileread.blob.core.windows.net/danyal\n",
    "\n",
    "def create_account_sas(account_name: str, account_key: str):\n",
    "    # Create an account SAS that's valid for one day\n",
    "    start_time = datetime.utcnow()\n",
    "    expiry_time = start_time + timedelta(days=1)\n",
    "\n",
    "    # Define the SAS token permissions\n",
    "    sas_permissions=AccountSasPermissions(list=True)\n",
    "\n",
    "    # Define the SAS token resource types\n",
    "    # For this example, we grant access to service-level APIs\n",
    "    sas_resource_types=ResourceTypes(container=True)\n",
    "\n",
    "    sas_token = generate_account_sas(\n",
    "        account_name=account_name,\n",
    "        account_key=account_key,\n",
    "        resource_types=sas_resource_types,\n",
    "        permission=sas_permissions,\n",
    "        expiry=expiry_time,\n",
    "        start=start_time\n",
    "    )\n",
    "\n",
    "    return sas_token\n",
    "\n",
    "# Creating service client var \n",
    "blob_service_client = BlobServiceClient(account_url=f\"https://denemefileread.blob.core.windows.net\"\n",
    "                                        , credential=create_account_sas(\"denemefileread\",\"qjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\"))\n",
    "container_client = blob_service_client.get_container_client(\"danyal\")\n",
    "# blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "# container_client.download_blob().readall()\n",
    "\n",
    "\n",
    "blob_list = container_client.list_blobs()\n",
    "for blob in blob_list:\n",
    "    current_blob = blob.name\n",
    "    source = \"https://denemefileread.blob.core.windows.net/danyal/\" + current_blob\n",
    "    df = pd.read_csv(source)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "# container_client.readall()\n",
    "# print(blob_list)\n",
    "\n",
    "# df = pd.read_csv(container_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read multiple CSV files from local file storage and apply all methods of dat package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset_analysis_saved'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saves seperate analysis report for all particular files in file storage\n",
    "\n",
    "dat.multiple_dataset_apply(\"C:/Users/MeliaMuyo/Desktop/multiple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Loop Values for Analysis Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling function/method names from analysis_dict.py file (user selective)\n",
    "functions_df_names = dat.analysis_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in functions_df_names.items():\n",
    "    # Creating dataframes defined on analysis_dict.py file\n",
    "    vars()[key] = value(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving dataframes created in session into one excel sheet in different tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "col_types\n",
      "shape\n",
      "describe_non_num\n",
      "duplicate_count\n",
      "unique_cols\n",
      "null_counts\n",
      "json_cols\n",
      "xml_cols\n",
      "date_cols\n",
      "value_counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'saved to excel'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.save_dataframe_excel(globals(),f\"analysis_dataset_{date.today()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c20fde216d2155112c50961c43343037d5dc4859966493adc092aeb7349463d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
