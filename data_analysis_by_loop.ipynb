{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from azure.storage.blob import BlobServiceClient, generate_account_sas, ResourceTypes, AccountSasPermissions, BlobBlock\n",
    "from datetime import datetime, timedelta, date\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "from collections import deque\n",
    "import dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset from cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dat' has no attribute 'df_read_azure_single_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# df = dat.df_read_aws(\"aws\",\"merkle-de-interview-case-study/de\",\"item.csv\")\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# In case needed df_read_azure method is available in dat package for azure blob reads\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_read_azure_single_file\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdenemefileread\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdanyal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dat' has no attribute 'df_read_azure_single_file'"
     ]
    }
   ],
   "source": [
    "# df = dat.df_read_aws(\"aws\",\"merkle-de-interview-case-study/de\",\"item.csv\")\n",
    "# In case needed df_read_azure method is available in dat package for azure blob reads\n",
    "df = dat.df_read_azure_single_file(\"denemefileread\",\"qjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\",\"event.csv\",\"danyal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dat' has no attribute 'df_read_azure_multiple_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_read_azure_multiple_files\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdenemefileread\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdanyal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dat' has no attribute 'df_read_azure_multiple_files'"
     ]
    }
   ],
   "source": [
    "dat.df_read_azure_multiple_files(\"denemefileread\"\"qjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\",\"danyal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             event_id       event_time  user_id  \\\n",
      "0    b9de71c5c3cc4cd7a97e50b832106e5a  6/26/2017 11:23   178481   \n",
      "1    23267713c9ea44419331731f50b6a8db  6/27/2017 10:46   178481   \n",
      "2    1b7822fa7b854e01970218ae8f721fe0  6/27/2017 11:15   178481   \n",
      "3    2a7a188a626841ac94befcc419f06af4  10/5/2016 20:43   154133   \n",
      "4    631d657264cc4616a4528f759509b25d   10/4/2016 3:29   154133   \n",
      "..                                ...              ...      ...   \n",
      "994  381b43fc776647a0bb33693e5bc4c4d4  10/4/2016 16:16   119909   \n",
      "995  73eca6e3d9eb4d0ead7eeb76e6525faa  10/1/2016 10:15   119909   \n",
      "996  a8418cc9dd1c4764a8411e5e7b42a111  10/3/2016 14:07   119909   \n",
      "997  e55dfd6c85d846fe8bd937476f7877e9    7/8/2016 5:29   110128   \n",
      "998  a4f9574c14894c8d9732167760dab92d   7/9/2016 16:28   110128   \n",
      "\n",
      "                                         event.payload  \n",
      "0    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "1    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "2    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "3    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "4    {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "..                                                 ...  \n",
      "994  {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "995  {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "996  {\"event_name\":\"view_item\",\"platform\":\"android\"...  \n",
      "997  {\"event_name\":\"view_item\",\"platform\":\"iOS\",\"pa...  \n",
      "998  {\"event_name\":\"view_item\",\"platform\":\"iOS\",\"pa...  \n",
      "\n",
      "[999 rows x 4 columns]\n",
      "                adjective     category           created_at      id  \\\n",
      "0                   fuzzy  contraption  2014-01-15 21:36:09  2512.0   \n",
      "1                     NaN   instrument  2013-05-14 05:20:50   482.0   \n",
      "2     industrial-strength       module  2014-02-04 19:28:32  2446.0   \n",
      "3                 digital         tool  2013-02-25 12:23:18  1312.0   \n",
      "4               miniature       device  2013-08-05 17:20:45  3556.0   \n",
      "...                   ...          ...                  ...     ...   \n",
      "2193        prize-winning    apparatus  2013-08-13 04:14:14  3952.0   \n",
      "2194                fuzzy       dongle  2014-01-16 00:58:43   432.0   \n",
      "2195  industrial-strength       dongle  2013-12-18 21:37:01  1393.0   \n",
      "2196            miniature       device  2013-11-27 14:14:47   425.0   \n",
      "2197                  NaN       widget  2013-10-10 21:13:50   325.0   \n",
      "\n",
      "           modifier                               name  price  \n",
      "0     carrying_case    fuzzy contraption carrying_case  150.0  \n",
      "1            refill                  instrument refill   35.2  \n",
      "2               NaN         industrial-strength module  300.0  \n",
      "3     carrying_case         digital tool carrying_case   16.5  \n",
      "4           cleaner           miniature device cleaner   16.5  \n",
      "...             ...                                ...    ...  \n",
      "2193        charger    prize-winning apparatus charger   66.0  \n",
      "2194        wrapper               fuzzy dongle wrapper   12.0  \n",
      "2195         refill  industrial-strength dongle refill   72.0  \n",
      "2196            NaN                   miniature device   27.5  \n",
      "2197  how-to-manual               widget how-to-manual    0.0  \n",
      "\n",
      "[2198 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# https://denemefileread.blob.core.windows.net/danyal\n",
    "\n",
    "def create_account_sas(account_name: str, account_key: str):\n",
    "    # Create an account SAS that's valid for one day\n",
    "    start_time = datetime.utcnow()\n",
    "    expiry_time = start_time + timedelta(days=1)\n",
    "\n",
    "    # Define the SAS token permissions\n",
    "    sas_permissions=AccountSasPermissions(list=True)\n",
    "\n",
    "    # Define the SAS token resource types\n",
    "    # For this example, we grant access to service-level APIs\n",
    "    sas_resource_types=ResourceTypes(container=True)\n",
    "\n",
    "    sas_token = generate_account_sas(\n",
    "        account_name=account_name,\n",
    "        account_key=account_key,\n",
    "        resource_types=sas_resource_types,\n",
    "        permission=sas_permissions,\n",
    "        expiry=expiry_time,\n",
    "        start=start_time\n",
    "    )\n",
    "\n",
    "    return sas_token\n",
    "\n",
    "# Creating service client var \n",
    "blob_service_client = BlobServiceClient(account_url=f\"https://denemefileread.blob.core.windows.net\"\n",
    "                                        , credential=create_account_sas(\"denemefileread\",\"qjuTRY15cF0ud5Tr051JjnmPaXtMjUcO5sNuC0rtHRPjMidGcYTPVO5JbF6QU5G/3GHcXy0eJg2h+AStpbSX2w==\"))\n",
    "container_client = blob_service_client.get_container_client(\"danyal\")\n",
    "# blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "# container_client.download_blob().readall()\n",
    "\n",
    "\n",
    "blob_list = container_client.list_blobs()\n",
    "for blob in blob_list:\n",
    "    current_blob = blob.name\n",
    "    source = \"https://denemefileread.blob.core.windows.net/danyal/\" + current_blob\n",
    "    df = pd.read_csv(source)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "# container_client.readall()\n",
    "# print(blob_list)\n",
    "\n",
    "# df = pd.read_csv(container_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read multiple CSV files from local file storage and apply all methods of dat package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset_analysis_saved'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saves seperate analysis report for all particular files in file storage\n",
    "\n",
    "dat.multiple_dataset_apply(\"C:/Users/MeliaMuyo/Desktop/multiple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Loop Values for Analysis Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling function/method names from analysis_dict.py file (user selective)\n",
    "functions_df_names = dat.analysis_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in functions_df_names.items():\n",
    "    # Creating dataframes defined on analysis_dict.py file\n",
    "    vars()[key] = value(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving dataframes created in session into one excel sheet in different tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "col_types\n",
      "shape\n",
      "describe_non_num\n",
      "duplicate_count\n",
      "unique_cols\n",
      "null_counts\n",
      "json_cols\n",
      "xml_cols\n",
      "date_cols\n",
      "value_counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'saved to excel'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.save_dataframe_excel(globals(),f\"analysis_dataset_{date.today()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c20fde216d2155112c50961c43343037d5dc4859966493adc092aeb7349463d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
