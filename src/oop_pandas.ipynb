{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dat\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import mysql.connector\n",
    "from datetime import datetime, timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mysql_profiler:\n",
    "    '''Class to create quick profiling of tables located on mysql server'''\n",
    "\n",
    "    def __init__(self,host,user,password,database,df) -> None:\n",
    "        self.df = df\n",
    "        self.host = host\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.database = database\n",
    "        \n",
    "    def multiple_dataset_apply_mysql(host:str, user:str, password:str, database:str):\n",
    "        ''' This function reads multiple tables from connected database as parameter \n",
    "        then runs all functions on dat package to read table '''\n",
    "\n",
    "        #Regex pattern for date columns\n",
    "        pattern_d = re.compile(r\"[0-9]{4}.[0-9]{2}.[0-9]{2}.*\", re.IGNORECASE)\n",
    "        pattern_d_alt = re.compile(r\"[0-9]{2}.[0-9]{2}.[0-9]{4}.*\", re.IGNORECASE)\n",
    "\n",
    "        # Creating connection string\n",
    "        db=mysql.connector.connect(host = str(host), user = str(user), password = str(password), database = str(database))\n",
    "        cursor=db.cursor()\n",
    "        cursor.execute(\"SHOW TABLES\")\n",
    "        myresult = cursor.fetchall()\n",
    "\n",
    "        # saving all tables of database into a list\n",
    "        read_table_names = [table_name[0] for table_name in myresult]\n",
    "\n",
    "        # Dict for dataframes that has read from database\n",
    "        dataframes_dict = {}\n",
    "\n",
    "        # Creating working directory for daily partitioning\n",
    "        dir = os.path.join(\"C:\\\\\", \"Users\\Lenovo\\Desktop\\exam_eti\\containerized_tool\\data_analysis_tool\", f'{date.today()}')\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "        os.chdir(dir)\n",
    "\n",
    "        # loop over the list of sql tables and read them into pandas dataframe\n",
    "        for f in read_table_names:\n",
    "            df = pd.read_sql(f'SELECT * FROM {f}', con=db)\n",
    "            # Creating a dict consisting of all dataframes\n",
    "            if df.size != 0:\n",
    "                dataframes_dict[f] = df  \n",
    "            # Applying methods to dataframes defined on analysis_dict.py file\n",
    "            for key,value in dat.analysis_dict().items():\n",
    "                if df.size != 0:\n",
    "                    vars()[key] = value(df)\n",
    "                    dat.save_dataframe_excel(vars(),f\"analysis_{f}_{date.today()}\")\n",
    "                else:\n",
    "                    dat.save_dataframe_excel(df,f\"analysis_{f}_{date.today()}\")\n",
    "        return \"methods applied xlsx file saved\",dataframes_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
